{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9c8f1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92         6\n",
      "           1       1.00      1.00      1.00        70\n",
      "           2       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           0.99       100\n",
      "   macro avg       0.95      0.99      0.97       100\n",
      "weighted avg       0.99      0.99      0.99       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"student_performance_dataset.csv\")\n",
    "\n",
    "# Drop Student_ID since it's not a predictor\n",
    "df.drop(columns=[\"Student_ID\"], inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "categorical_columns = [\"Gender\", \"Parental_Education_Level\", \"Extra_Curricular_Activities\", \"Internet_Access_at_Home\", \"Socioeconomic_Status\", \"Health_Issues\"]\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode target variable\n",
    "le_target = LabelEncoder()\n",
    "df[\"Final_Performance\"] = le_target.fit_transform(df[\"Final_Performance\"])\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(columns=[\"Final_Performance\"])\n",
    "y = df[\"Final_Performance\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41b31d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Performance: Low\n"
     ]
    }
   ],
   "source": [
    "# Simple Prediction Function\n",
    "def predict_performance(input_data):\n",
    "    input_df = pd.DataFrame([input_data], columns=X.columns)\n",
    "    for col in categorical_columns:\n",
    "        input_df[col] = label_encoders[col].transform(input_df[col])\n",
    "    input_df = scaler.transform(input_df)\n",
    "    prediction = model.predict(input_df)\n",
    "    return le_target.inverse_transform(prediction)[0]\n",
    "\n",
    "# Example Usage\n",
    "example_input = {\n",
    "    \"Age\": 20,\n",
    "    \"Gender\": \"Male\",\n",
    "    \"Study_Hours_per_Week\": 0,\n",
    "    \"Previous_Scores\": 75,\n",
    "    \"Class_Participation\": 60,\n",
    "    \"Attendance_Rate\": 95,\n",
    "    \"Parental_Education_Level\": \"Higher\",\n",
    "    \"Extra_Curricular_Activities\": \"Yes\",\n",
    "    \"Internet_Access_at_Home\": \"Yes\",\n",
    "    \"Socioeconomic_Status\": \"Medium\",\n",
    "    \"Health_Issues\": \"No\"\n",
    "}\n",
    "\n",
    "predicted_performance = predict_performance(example_input)\n",
    "print(f\"Predicted Performance: {predicted_performance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31eea269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.24\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.23      0.22        30\n",
      "           1       0.36      0.15      0.21        27\n",
      "           2       0.17      0.32      0.22        22\n",
      "           3       0.43      0.29      0.34        21\n",
      "\n",
      "    accuracy                           0.24       100\n",
      "   macro avg       0.29      0.25      0.25       100\n",
      "weighted avg       0.29      0.24      0.24       100\n",
      "\n",
      "Predicted Performance: Good\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"student_performance_datasets.csv\")\n",
    "\n",
    "# Drop Student_ID since it's not a predictor\n",
    "df.drop(columns=[\"Student_ID\"], inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "categorical_columns = [\n",
    "    \"Gender\", \"Parental_Education_Level\", \"Extra_Curricular_Activities\", \"Internet_Access_at_Home\", \n",
    "    \"Socioeconomic_Status\", \"Health_Issues\", \"Motivation_Level\", \"Peer_Influence\", \"Time_Management_Skills\",\n",
    "    \"Family_Support\", \"Stress_Level\", \"Learning_Style\"\n",
    "]\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode target variable\n",
    "le_target = LabelEncoder()\n",
    "df[\"Final_Performance\"] = le_target.fit_transform(df[\"Final_Performance\"])\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(columns=[\"Final_Performance\"])\n",
    "y = df[\"Final_Performance\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Simple Prediction Function\n",
    "def predict_performance(input_data):\n",
    "    input_df = pd.DataFrame([input_data], columns=X.columns)\n",
    "    for col in categorical_columns:\n",
    "        input_df[col] = label_encoders[col].transform(input_df[col])\n",
    "    input_df = scaler.transform(input_df)\n",
    "    prediction = model.predict(input_df)\n",
    "    return le_target.inverse_transform(prediction)[0]\n",
    "\n",
    "# Example Usage\n",
    "example_input = {\n",
    "    \"Age\": 20,\n",
    "    \"Gender\": \"Male\",\n",
    "    \"Study_Hours_per_Week\": 25,\n",
    "    \"Previous_Scores\": 85,\n",
    "    \"Class_Participation\": 90,\n",
    "    \"Attendance_Rate\": 95,\n",
    "    \"Parental_Education_Level\": \"Higher\",\n",
    "    \"Extra_Curricular_Activities\": \"Yes\",\n",
    "    \"Internet_Access_at_Home\": \"Yes\",\n",
    "    \"Socioeconomic_Status\": \"Medium\",\n",
    "    \"Health_Issues\": \"No\",\n",
    "    \"Motivation_Level\": \"High\",\n",
    "    \"Peer_Influence\": \"Positive\",\n",
    "    \"Time_Management_Skills\": \"Good\",\n",
    "    \"Family_Support\": \"Strong\",\n",
    "    \"Stress_Level\": \"Low\",\n",
    "    \"Learning_Style\": \"Visual\"\n",
    "}\n",
    "\n",
    "predicted_performance = predict_performance(example_input)\n",
    "print(f\"Predicted Performance: {predicted_performance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f61daddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        10\n",
      "           1       0.94      1.00      0.97       103\n",
      "           2       0.94      0.84      0.89        37\n",
      "\n",
      "    accuracy                           0.95       150\n",
      "   macro avg       0.96      0.88      0.92       150\n",
      "weighted avg       0.95      0.95      0.94       150\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [3.7704777574151302]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14240\\3500621434.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m }\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m \u001b[0mpredicted_performance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Predicted Performance: {predicted_performance}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14240\\3490534909.py\u001b[0m in \u001b[0;36mpredict_performance\u001b[1;34m(input_data)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# Apply label encoding to categorical columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcategorical_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0minput_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_encoders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# Standardize the numerical features (apply scaling)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_unknown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"y contains previously unseen labels: {str(diff)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: [3.7704777574151302]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"student_performance_datasetdf.csv\")\n",
    "\n",
    "# Drop Student_ID since it's not a predictor\n",
    "\n",
    "df.drop(columns=[\"Student_ID\"], inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "categorical_columns = [\"Gender\", \"Parental_Education_Level\", \n",
    "                       \"Extra_Curricular_Activities\", \"Internet_Access_at_Home\", \n",
    "                       \"Socioeconomic_Status\", \"Health_Issues\", \n",
    "                      \"Previous_GPA\", \"Peer_Influence\",\"Time_Management_Skills\",\n",
    "                       \"Family_Support\", \"Stress_Level\"]\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode target variable\n",
    "le_target = LabelEncoder()\n",
    "df[\"Final_Performance\"] = le_target.fit_transform(df[\"Final_Performance\"])\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(columns=[\"Final_Performance\"])\n",
    "y = df[\"Final_Performance\"]\n",
    "\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Example Usage\n",
    "example_input = {\n",
    "    \"Age\": 20,\n",
    "    \"Gender\": \"Male\",\n",
    "    \"Study_Hours_per_Week\": 25,\n",
    "    \"Previous_Scores\": 15,\n",
    "    \"Class_Participation\": 90,\n",
    "    \"Attendance_Rate\": 15,\n",
    "    \"Parental_Education_Level\": \"Higher\",\n",
    "    \"Extra_Curricular_Activities\": \"Yes\",\n",
    "    \"Internet_Access_at_Home\": \"Yes\",\n",
    "    \"Socioeconomic_Status\": \"Medium\",\n",
    "    \"Health_Issues\": \"No\",\n",
    "    \"Previous_GPA\": 3.5,\n",
    "    \"Motivation_Level\": \"High\",\n",
    "    \"Peer_Influence\": \"Positive\",\n",
    "    \"Time_Management_Skills\": \"Good\",\n",
    "    \"Family_Support\": \"Strong\"\n",
    "    \n",
    "}\n",
    "\n",
    "predicted_performance = predict_performance(example_input)\n",
    "print(f\"Predicted Performance: {predicted_performance}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
